openapi: 3.1.0
info:
  title: Hermes API
  version: 1.0.0
  description: |
    Canonical Hermes OpenAPI contract for Project LOGOS.
    See Project LOGOS spec: Table 2 in Section 3.4 (Hermes API endpoints).
    
    Hermes is the stateless language & embedding utility providing:
    - Speech-to-text (STT)
    - Text-to-speech (TTS)
    - Simple NLP preprocessing
    - Text embedding generation
    - LLM gateway proxy via `/llm`
    
    All endpoints are stateless and do not interact with the HCG directly.

servers:
  - url: http://localhost:8080
    description: Local development server

paths:
  /stt:
    post:
      summary: Speech-to-Text
      description: Convert audio input to text transcription
      operationId: speechToText
      requestBody:
        required: true
        content:
          multipart/form-data:
            schema:
              type: object
              properties:
                audio:
                  type: string
                  format: binary
                  description: Audio file to transcribe
                language:
                  type: string
                  description: Optional language hint (e.g., "en-US")
                  default: "en-US"
              required:
                - audio
      responses:
        '200':
          description: Transcription successful
          content:
            application/json:
              schema:
                type: object
                properties:
                  text:
                    type: string
                    description: Transcribed text
                  confidence:
                    type: number
                    format: float
                    description: Confidence score (0.0 to 1.0)
        '400':
          description: Invalid request (e.g., unsupported audio format)
        '500':
          description: Internal server error

  /tts:
    post:
      summary: Text-to-Speech
      description: Convert text to synthesized speech audio
      operationId: textToSpeech
      requestBody:
        required: true
        content:
          application/json:
            schema:
              type: object
              properties:
                text:
                  type: string
                  description: Text to synthesize
                voice:
                  type: string
                  description: Optional voice identifier
                  default: "default"
                language:
                  type: string
                  description: Language code (e.g., "en-US")
                  default: "en-US"
              required:
                - text
      responses:
        '200':
          description: Speech synthesis successful
          content:
            audio/wav:
              schema:
                type: string
                format: binary
        '400':
          description: Invalid request
        '500':
          description: Internal server error

  /simple_nlp:
    post:
      summary: Simple NLP Preprocessing
      description: Perform basic NLP preprocessing (tokenization, POS tagging, etc.)
      operationId: simpleNlp
      requestBody:
        required: true
        content:
          application/json:
            schema:
              type: object
              properties:
                text:
                  type: string
                  description: Text to process
                operations:
                  type: array
                  items:
                    type: string
                    enum: [tokenize, pos_tag, lemmatize, ner]
                  description: List of NLP operations to perform
                  default: [tokenize]
              required:
                - text
      responses:
        '200':
          description: NLP processing successful
          content:
            application/json:
              schema:
                type: object
                properties:
                  tokens:
                    type: array
                    items:
                      type: string
                    description: Tokenized text (if requested)
                  pos_tags:
                    type: array
                    items:
                      type: object
                      properties:
                        token:
                          type: string
                        tag:
                          type: string
                    description: POS tags (if requested)
                  lemmas:
                    type: array
                    items:
                      type: string
                    description: Lemmatized tokens (if requested)
                  entities:
                    type: array
                    items:
                      type: object
                      properties:
                        text:
                          type: string
                        label:
                          type: string
                        start:
                          type: integer
                        end:
                          type: integer
                    description: Named entities (if requested)
        '400':
          description: Invalid request
        '500':
          description: Internal server error

  /embed_text:
    post:
      summary: Text Embedding Generation
      description: Generate vector embeddings for input text
      operationId: embedText
      requestBody:
        required: true
        content:
          application/json:
            schema:
              type: object
              properties:
                text:
                  type: string
                  description: Text to embed
                model:
                  type: string
                  description: Optional embedding model identifier
                  default: "default"
              required:
                - text
      responses:
        '200':
          description: Embedding generation successful
          content:
            application/json:
              schema:
                type: object
                properties:
                  embedding:
                    type: array
                    items:
                      type: number
                      format: float
                    description: Vector embedding
                  dimension:
                    type: integer
                    description: Embedding dimension
                  model:
                    type: string
                    description: Model used for embedding
        '400':
          description: Invalid request
        '500':
          description: Internal server error

  /llm:
    post:
      summary: LLM Gateway
      description: Proxy chat/completion requests through the configured provider (OpenAI, local, or echo fallback).
      operationId: llmGenerate
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/LLMRequest'
      responses:
        '200':
          description: Completion generated successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/LLMResponse'
        '400':
          description: Invalid request (missing prompt/messages or schema violation)
        '502':
          description: Provider returned an error response
        '503':
          description: Provider not configured/available
        '500':
          description: Internal server error

components:
  schemas:
    LLMMessage:
      type: object
      description: Chat completion message payload.
      required:
        - role
        - content
      properties:
        role:
          type: string
          description: Role associated with the message.
          enum: [system, user, assistant, tool]
        content:
          type: string
          description: Text content of the message.
        name:
          type: string
          description: Optional identifier for tool/function calls.
    LLMChoice:
      type: object
      description: Individual choice returned by the provider.
      required:
        - index
        - message
      properties:
        index:
          type: integer
          description: Choice index.
        message:
          $ref: '#/components/schemas/LLMMessage'
        finish_reason:
          type: string
          description: Reason generation finished (e.g., `stop`, `length`).
    LLMUsage:
      type: object
      description: Token usage returned by the upstream provider.
      required:
        - prompt_tokens
        - completion_tokens
        - total_tokens
      properties:
        prompt_tokens:
          type: integer
          description: Prompt token count.
        completion_tokens:
          type: integer
          description: Completion token count.
        total_tokens:
          type: integer
          description: Total token count.
    LLMResponse:
      type: object
      description: Standardized completion response returned by Hermes.
      required:
        - id
        - provider
        - model
        - created
        - choices
      properties:
        id:
          type: string
          description: Provider response identifier.
        provider:
          type: string
          description: Provider used for this completion.
        model:
          type: string
          description: Provider model identifier.
        created:
          type: integer
          format: int64
          description: Unix timestamp indicating when the provider generated the response.
        choices:
          type: array
          description: Choice payloads returned by the provider.
          items:
            $ref: '#/components/schemas/LLMChoice'
        usage:
          $ref: '#/components/schemas/LLMUsage'
          nullable: true
        raw:
          type: object
          description: Raw provider payload for diagnostics.
          additionalProperties: true
          nullable: true
    LLMRequest:
      type: object
      description: Request payload for Hermes LLM gateway.
      properties:
        prompt:
          type: string
          description: Shortcut for a single user message when `messages` is omitted.
        messages:
          type: array
          description: Conversation history forwarded to the provider.
          items:
            $ref: '#/components/schemas/LLMMessage'
        provider:
          type: string
          description: Override the configured provider (e.g., `openai`, `echo`, `local`).
        model:
          type: string
          description: Provider-specific model identifier override.
        temperature:
          type: number
          format: float
          description: Sampling temperature forwarded to the provider.
          minimum: 0
          maximum: 2
          default: 0.7
        max_tokens:
          type: integer
          description: Optional maximum number of tokens to generate.
          minimum: 1
        metadata:
          type: object
          description: Additional metadata stored alongside the request.
          additionalProperties: true
      anyOf:
        - required: [prompt]
        - required: [messages]
