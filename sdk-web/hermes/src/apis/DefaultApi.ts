/* tslint:disable */
/* eslint-disable */
/**
 * Hermes API
 * Canonical Hermes OpenAPI contract for Project LOGOS. See Project LOGOS spec: Table 2 in Section 3.4 (Hermes API endpoints).  Hermes is the stateless language & embedding utility providing: - Speech-to-text (STT) - Text-to-speech (TTS) - Simple NLP preprocessing - Text embedding generation - LLM gateway proxy via `/llm`  All endpoints are stateless and do not interact with the HCG directly. 
 *
 * The version of the OpenAPI document: 1.0.0
 * 
 *
 * NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
 * https://openapi-generator.tech
 * Do not edit the class manually.
 */


import * as runtime from '../runtime';
import type {
  EmbedText200Response,
  EmbedTextRequest,
  LLMRequest,
  LLMResponse,
  SimpleNlp200Response,
  SimpleNlpRequest,
  SpeechToText200Response,
  TextToSpeechRequest,
} from '../models/index';
import {
    EmbedText200ResponseFromJSON,
    EmbedText200ResponseToJSON,
    EmbedTextRequestFromJSON,
    EmbedTextRequestToJSON,
    LLMRequestFromJSON,
    LLMRequestToJSON,
    LLMResponseFromJSON,
    LLMResponseToJSON,
    SimpleNlp200ResponseFromJSON,
    SimpleNlp200ResponseToJSON,
    SimpleNlpRequestFromJSON,
    SimpleNlpRequestToJSON,
    SpeechToText200ResponseFromJSON,
    SpeechToText200ResponseToJSON,
    TextToSpeechRequestFromJSON,
    TextToSpeechRequestToJSON,
} from '../models/index';

export interface EmbedTextOperationRequest {
    embedTextRequest: EmbedTextRequest;
}

export interface LlmGenerateRequest {
    lLMRequest: LLMRequest | null;
}

export interface SimpleNlpOperationRequest {
    simpleNlpRequest: SimpleNlpRequest;
}

export interface SpeechToTextRequest {
    audio: Blob;
    language?: string;
}

export interface TextToSpeechOperationRequest {
    textToSpeechRequest: TextToSpeechRequest;
}

/**
 * 
 */
export class DefaultApi extends runtime.BaseAPI {

    /**
     * Generate vector embeddings for input text
     * Text Embedding Generation
     */
    async embedTextRaw(requestParameters: EmbedTextOperationRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<EmbedText200Response>> {
        if (requestParameters['embedTextRequest'] == null) {
            throw new runtime.RequiredError(
                'embedTextRequest',
                'Required parameter "embedTextRequest" was null or undefined when calling embedText().'
            );
        }

        const queryParameters: any = {};

        const headerParameters: runtime.HTTPHeaders = {};

        headerParameters['Content-Type'] = 'application/json';


        let urlPath = `/embed_text`;

        const response = await this.request({
            path: urlPath,
            method: 'POST',
            headers: headerParameters,
            query: queryParameters,
            body: EmbedTextRequestToJSON(requestParameters['embedTextRequest']),
        }, initOverrides);

        return new runtime.JSONApiResponse(response, (jsonValue) => EmbedText200ResponseFromJSON(jsonValue));
    }

    /**
     * Generate vector embeddings for input text
     * Text Embedding Generation
     */
    async embedText(requestParameters: EmbedTextOperationRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<EmbedText200Response> {
        const response = await this.embedTextRaw(requestParameters, initOverrides);
        return await response.value();
    }

    /**
     * Proxy chat/completion requests through the configured provider (OpenAI, local, or echo fallback).
     * LLM Gateway
     */
    async llmGenerateRaw(requestParameters: LlmGenerateRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<LLMResponse>> {
        if (requestParameters['lLMRequest'] == null) {
            throw new runtime.RequiredError(
                'lLMRequest',
                'Required parameter "lLMRequest" was null or undefined when calling llmGenerate().'
            );
        }

        const queryParameters: any = {};

        const headerParameters: runtime.HTTPHeaders = {};

        headerParameters['Content-Type'] = 'application/json';


        let urlPath = `/llm`;

        const response = await this.request({
            path: urlPath,
            method: 'POST',
            headers: headerParameters,
            query: queryParameters,
            body: LLMRequestToJSON(requestParameters['lLMRequest']),
        }, initOverrides);

        return new runtime.JSONApiResponse(response, (jsonValue) => LLMResponseFromJSON(jsonValue));
    }

    /**
     * Proxy chat/completion requests through the configured provider (OpenAI, local, or echo fallback).
     * LLM Gateway
     */
    async llmGenerate(requestParameters: LlmGenerateRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<LLMResponse> {
        const response = await this.llmGenerateRaw(requestParameters, initOverrides);
        return await response.value();
    }

    /**
     * Perform basic NLP preprocessing (tokenization, POS tagging, etc.)
     * Simple NLP Preprocessing
     */
    async simpleNlpRaw(requestParameters: SimpleNlpOperationRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<SimpleNlp200Response>> {
        if (requestParameters['simpleNlpRequest'] == null) {
            throw new runtime.RequiredError(
                'simpleNlpRequest',
                'Required parameter "simpleNlpRequest" was null or undefined when calling simpleNlp().'
            );
        }

        const queryParameters: any = {};

        const headerParameters: runtime.HTTPHeaders = {};

        headerParameters['Content-Type'] = 'application/json';


        let urlPath = `/simple_nlp`;

        const response = await this.request({
            path: urlPath,
            method: 'POST',
            headers: headerParameters,
            query: queryParameters,
            body: SimpleNlpRequestToJSON(requestParameters['simpleNlpRequest']),
        }, initOverrides);

        return new runtime.JSONApiResponse(response, (jsonValue) => SimpleNlp200ResponseFromJSON(jsonValue));
    }

    /**
     * Perform basic NLP preprocessing (tokenization, POS tagging, etc.)
     * Simple NLP Preprocessing
     */
    async simpleNlp(requestParameters: SimpleNlpOperationRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<SimpleNlp200Response> {
        const response = await this.simpleNlpRaw(requestParameters, initOverrides);
        return await response.value();
    }

    /**
     * Convert audio input to text transcription
     * Speech-to-Text
     */
    async speechToTextRaw(requestParameters: SpeechToTextRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<SpeechToText200Response>> {
        if (requestParameters['audio'] == null) {
            throw new runtime.RequiredError(
                'audio',
                'Required parameter "audio" was null or undefined when calling speechToText().'
            );
        }

        const queryParameters: any = {};

        const headerParameters: runtime.HTTPHeaders = {};

        const consumes: runtime.Consume[] = [
            { contentType: 'multipart/form-data' },
        ];
        // @ts-ignore: canConsumeForm may be unused
        const canConsumeForm = runtime.canConsumeForm(consumes);

        let formParams: { append(param: string, value: any): any };
        let useForm = false;
        // use FormData to transmit files using content-type "multipart/form-data"
        useForm = canConsumeForm;
        if (useForm) {
            formParams = new FormData();
        } else {
            formParams = new URLSearchParams();
        }

        if (requestParameters['audio'] != null) {
            formParams.append('audio', requestParameters['audio'] as any);
        }

        if (requestParameters['language'] != null) {
            formParams.append('language', requestParameters['language'] as any);
        }


        let urlPath = `/stt`;

        const response = await this.request({
            path: urlPath,
            method: 'POST',
            headers: headerParameters,
            query: queryParameters,
            body: formParams,
        }, initOverrides);

        return new runtime.JSONApiResponse(response, (jsonValue) => SpeechToText200ResponseFromJSON(jsonValue));
    }

    /**
     * Convert audio input to text transcription
     * Speech-to-Text
     */
    async speechToText(requestParameters: SpeechToTextRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<SpeechToText200Response> {
        const response = await this.speechToTextRaw(requestParameters, initOverrides);
        return await response.value();
    }

    /**
     * Convert text to synthesized speech audio
     * Text-to-Speech
     */
    async textToSpeechRaw(requestParameters: TextToSpeechOperationRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<Blob>> {
        if (requestParameters['textToSpeechRequest'] == null) {
            throw new runtime.RequiredError(
                'textToSpeechRequest',
                'Required parameter "textToSpeechRequest" was null or undefined when calling textToSpeech().'
            );
        }

        const queryParameters: any = {};

        const headerParameters: runtime.HTTPHeaders = {};

        headerParameters['Content-Type'] = 'application/json';


        let urlPath = `/tts`;

        const response = await this.request({
            path: urlPath,
            method: 'POST',
            headers: headerParameters,
            query: queryParameters,
            body: TextToSpeechRequestToJSON(requestParameters['textToSpeechRequest']),
        }, initOverrides);

        return new runtime.BlobApiResponse(response);
    }

    /**
     * Convert text to synthesized speech audio
     * Text-to-Speech
     */
    async textToSpeech(requestParameters: TextToSpeechOperationRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<Blob> {
        const response = await this.textToSpeechRaw(requestParameters, initOverrides);
        return await response.value();
    }

}
