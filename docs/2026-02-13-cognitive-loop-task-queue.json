[
  {
    "id": "00a",
    "group": "00-logos-redis-config",
    "depends_on": [],
    "title": "Add RedisConfig to logos_config/settings.py",
    "description": "Add a `RedisConfig` class to `/home/fearsidhe/projects/LOGOS/logos/logos_config/settings.py`, following the exact pattern of the existing `Neo4jConfig` (line 15) and `MilvusConfig` (line 51).\n\n**Implementation:**\n\nAdd after line 72 (end of `MilvusConfig`):\n\n```python\nclass RedisConfig(BaseSettings):\n    \"\"\"Redis connection configuration.\n\n    Env vars: REDIS_HOST, REDIS_PORT, REDIS_DB\n    \"\"\"\n\n    model_config = SettingsConfigDict(env_prefix=\"REDIS_\")\n\n    host: str = Field(default=\"localhost\")\n    port: int = Field(default=6379)\n    db: int = Field(default=0)\n\n    @property\n    def url(self) -> str:\n        \"\"\"Return the redis:// connection URL.\"\"\"\n        return f\"redis://{self.host}:{self.port}/{self.db}\"\n```\n\nThen update `/home/fearsidhe/projects/LOGOS/logos/logos_config/__init__.py`:\n- Add `RedisConfig` to the import from `logos_config.settings`\n- Add `\"RedisConfig\"` to the `__all__` list\n\n**Test file:** Create `/home/fearsidhe/projects/LOGOS/logos/tests/test_redis_config.py`:\n\n```python\n\"\"\"Tests for RedisConfig in logos_config.\"\"\"\nfrom logos_config import RedisConfig\n\n\ndef test_redis_config_defaults():\n    config = RedisConfig()\n    assert config.host == \"localhost\"\n    assert config.port == 6379\n    assert config.db == 0\n    assert config.url == \"redis://localhost:6379/0\"\n\n\ndef test_redis_config_env_prefix(monkeypatch):\n    monkeypatch.setenv(\"REDIS_HOST\", \"redis-service\")\n    monkeypatch.setenv(\"REDIS_PORT\", \"46379\")\n    monkeypatch.setenv(\"REDIS_DB\", \"2\")\n    config = RedisConfig()\n    assert config.host == \"redis-service\"\n    assert config.port == 46379\n    assert config.db == 2\n    assert config.url == \"redis://redis-service:46379/2\"\n\n\ndef test_redis_config_importable():\n    from logos_config import RedisConfig as RC\n    assert RC is not None\n```\n\n**Run:** `cd /home/fearsidhe/projects/LOGOS/logos && poetry run pytest tests/test_redis_config.py -v`\n\n**Compatibility note:** Sophia's existing `feedback/config.py` uses `redis_url = \"redis://localhost:6379/0\"` as its default. The `RedisConfig.url` property produces the same format, so downstream consumers can use `RedisConfig().url` as a drop-in.",
    "status": "pending"
  },
  {
    "id": "00b",
    "group": "00-logos-redis-config",
    "depends_on": ["00a"],
    "title": "Add redis port to RepoPorts and hermes test compose",
    "description": "Add `redis` field to the `RepoPorts` NamedTuple in `/home/fearsidhe/projects/LOGOS/logos/logos_config/ports.py` and add a Redis service to the hermes test docker-compose.\n\n**1. Update ports.py**\n\nFile: `/home/fearsidhe/projects/LOGOS/logos/logos_config/ports.py`\n\nThe `RepoPorts` NamedTuple (line 27) currently has: `neo4j_http, neo4j_bolt, milvus_grpc, milvus_metrics, api`. Add `redis: int` as the last field:\n\n```python\nclass RepoPorts(NamedTuple):\n    \"\"\"Port configuration for a repo.\"\"\"\n    neo4j_http: int\n    neo4j_bolt: int\n    milvus_grpc: int\n    milvus_metrics: int\n    api: int\n    redis: int\n```\n\nUpdate all five constants (around lines 32-36):\n```python\nHERMES_PORTS = RepoPorts(17474, 17687, 17530, 17091, 17000, 16379)\nAPOLLO_PORTS = RepoPorts(27474, 27687, 27530, 27091, 27000, 26379)\nLOGOS_PORTS = RepoPorts(37474, 37687, 37530, 37091, 37000, 36379)\nSOPHIA_PORTS = RepoPorts(47474, 47687, 47530, 47091, 47000, 46379)\nTALOS_PORTS = RepoPorts(57474, 57687, 57530, 57091, 57000, 56379)\n```\n\nIn `get_repo_ports()` (around line 65), add to the returned `RepoPorts`:\n```python\n    redis=get_port(\"REDIS_PORT\", defaults.redis),\n```\n\n**2. Add Redis to hermes test compose**\n\nFile: `/home/fearsidhe/projects/LOGOS/hermes/tests/e2e/stack/hermes/docker-compose.test.yml`\n\nThis file currently has Neo4j (ports 17474/17687) and Milvus (port 17530) services on the `logos-test-network`. Append this service to the `services:` block:\n\n```yaml\n  redis:\n    container_name: hermes-test-redis\n    image: redis:7-alpine\n    ports:\n    - 16379:6379\n    healthcheck:\n      test:\n      - CMD\n      - redis-cli\n      - ping\n      interval: 5s\n      timeout: 3s\n      retries: 3\n    networks:\n    - default\n```\n\n**Note:** Sophia's test compose at `sophia/containers/docker-compose.test.yml` already has Redis (`redis:7-alpine` on port `46379:6379`) — no changes needed there.\n\n**Test:** Run existing port tests: `cd /home/fearsidhe/projects/LOGOS/logos && poetry run pytest tests/ -k port -v`. Fix any that assert on tuple length.\n\n**Verify:** `grep -c redis /home/fearsidhe/projects/LOGOS/hermes/tests/e2e/stack/hermes/docker-compose.test.yml` should return > 0.",
    "status": "pending"
  },
  {
    "id": "01a",
    "group": "01-hermes-proposal-builder",
    "depends_on": [],
    "title": "Create ProposalBuilder with tests",
    "description": "Create `hermes/src/hermes/proposal_builder.py` — a module that builds graph-ready structured proposals from conversation turns by combining NER entity extraction with per-entity embedding generation.\n\n**Working directory:** `/home/fearsidhe/projects/LOGOS/hermes`\n\n**Existing services to use (do NOT reimplement):**\n- `hermes.services.process_nlp(text: str, operations: List[str]) -> Dict[str, Any]` — when called with `[\"ner\"]`, returns `{\"entities\": [{\"text\": str, \"label\": str, \"start\": int, \"end\": int}]}`\n- `hermes.services.generate_embedding(text: str, model_name: str = \"default\") -> Dict[str, Any]` — returns `{\"embedding\": List[float], \"dimension\": 384, \"model\": str, \"embedding_id\": str}`\n- Both are async functions.\n\n**Implementation:** Create `/home/fearsidhe/projects/LOGOS/hermes/src/hermes/proposal_builder.py`:\n\n```python\n\"\"\"Builds graph-ready structured proposals from conversation turns.\n\nHermes is the only language-capable component. This module translates\nfree-text conversation turns into structured data (entities + embeddings)\nthat Sophia can evaluate without understanding text.\n\"\"\"\n\nimport logging\nimport uuid\nfrom datetime import datetime, timezone\n\nfrom hermes.services import generate_embedding, process_nlp\n\nlogger = logging.getLogger(__name__)\n\n\nclass ProposalBuilder:\n    \"\"\"Builds structured proposals from conversation text.\"\"\"\n\n    async def build(\n        self,\n        raw_text: str,\n        metadata: dict | None = None,\n        correlation_id: str | None = None,\n        llm_provider: str = \"unknown\",\n        model: str = \"unknown\",\n        confidence: float = 0.7,\n    ) -> dict:\n        metadata = metadata or {}\n        proposal_id = str(uuid.uuid4())\n        correlation_id = correlation_id or str(uuid.uuid4())\n\n        # Extract entities via NER\n        proposed_nodes = []\n        try:\n            nlp_result = await process_nlp(raw_text, [\"ner\"])\n            entities = nlp_result.get(\"entities\", [])\n            for entity in entities:\n                entity_text = entity.get(\"text\", \"\").strip()\n                if not entity_text:\n                    continue\n                try:\n                    emb_result = await generate_embedding(entity_text)\n                    proposed_nodes.append({\n                        \"name\": entity_text,\n                        \"type\": entity.get(\"label\", \"UNKNOWN\"),\n                        \"embedding\": emb_result[\"embedding\"],\n                        \"embedding_id\": emb_result[\"embedding_id\"],\n                        \"dimension\": emb_result[\"dimension\"],\n                        \"model\": emb_result[\"model\"],\n                        \"properties\": {},\n                    })\n                except Exception as e:\n                    logger.warning(f\"Failed to embed entity '{entity_text}': {e}\")\n                    proposed_nodes.append({\n                        \"name\": entity_text,\n                        \"type\": entity.get(\"label\", \"UNKNOWN\"),\n                        \"embedding\": None, \"embedding_id\": None,\n                        \"dimension\": None, \"model\": None, \"properties\": {},\n                    })\n        except Exception as e:\n            logger.warning(f\"NER extraction failed: {e}\")\n\n        # Generate document-level embedding\n        document_embedding = {}\n        try:\n            doc_emb = await generate_embedding(raw_text)\n            document_embedding = {\n                \"embedding\": doc_emb[\"embedding\"],\n                \"embedding_id\": doc_emb[\"embedding_id\"],\n                \"dimension\": doc_emb[\"dimension\"],\n                \"model\": doc_emb[\"model\"],\n            }\n        except Exception as e:\n            logger.warning(f\"Document embedding failed: {e}\")\n\n        return {\n            \"proposal_id\": proposal_id,\n            \"correlation_id\": correlation_id,\n            \"source_service\": \"hermes\",\n            \"llm_provider\": llm_provider,\n            \"model\": model,\n            \"generated_at\": datetime.now(timezone.utc).isoformat(),\n            \"confidence\": confidence,\n            \"raw_text\": raw_text,\n            \"proposed_nodes\": proposed_nodes,\n            \"proposed_relationships\": [],\n            \"document_embedding\": document_embedding,\n            \"metadata\": metadata,\n        }\n```\n\n**Test file:** Create `/home/fearsidhe/projects/LOGOS/hermes/tests/hermes/test_proposal_builder.py`:\n\n```python\n\"\"\"Tests for ProposalBuilder.\"\"\"\nimport pytest\nfrom unittest.mock import AsyncMock, patch\n\n\n@pytest.mark.asyncio\nasync def test_build_proposal_returns_structured_output():\n    from hermes.proposal_builder import ProposalBuilder\n    builder = ProposalBuilder()\n    mock_nlp = {\"entities\": [\n        {\"text\": \"Alice\", \"label\": \"PERSON\", \"start\": 0, \"end\": 5},\n        {\"text\": \"Acme Corp\", \"label\": \"ORG\", \"start\": 15, \"end\": 24},\n    ]}\n    mock_emb = {\"embedding\": [0.1] * 384, \"dimension\": 384, \"model\": \"all-MiniLM-L6-v2\", \"embedding_id\": \"emb-001\"}\n    with patch(\"hermes.proposal_builder.process_nlp\", new_callable=AsyncMock, return_value=mock_nlp), \\\n         patch(\"hermes.proposal_builder.generate_embedding\", new_callable=AsyncMock, return_value=mock_emb):\n        proposal = await builder.build(raw_text=\"Alice works at Acme Corp.\", metadata={\"source\": \"hermes_llm\"})\n    assert len(proposal[\"proposed_nodes\"]) == 2\n    assert proposal[\"proposed_nodes\"][0][\"name\"] == \"Alice\"\n    assert proposal[\"proposed_nodes\"][0][\"type\"] == \"PERSON\"\n    assert proposal[\"document_embedding\"][\"embedding\"] == [0.1] * 384\n    assert proposal[\"source_service\"] == \"hermes\"\n\n\n@pytest.mark.asyncio\nasync def test_build_proposal_empty_entities():\n    from hermes.proposal_builder import ProposalBuilder\n    builder = ProposalBuilder()\n    mock_emb = {\"embedding\": [0.5] * 384, \"dimension\": 384, \"model\": \"all-MiniLM-L6-v2\", \"embedding_id\": \"emb-002\"}\n    with patch(\"hermes.proposal_builder.process_nlp\", new_callable=AsyncMock, return_value={\"entities\": []}), \\\n         patch(\"hermes.proposal_builder.generate_embedding\", new_callable=AsyncMock, return_value=mock_emb):\n        proposal = await builder.build(raw_text=\"Just a greeting.\", metadata={})\n    assert proposal[\"proposed_nodes\"] == []\n    assert proposal[\"proposed_relationships\"] == []\n    assert proposal[\"document_embedding\"][\"dimension\"] == 384\n\n\n@pytest.mark.asyncio\nasync def test_build_proposal_degrades_when_nlp_unavailable():\n    from hermes.proposal_builder import ProposalBuilder\n    builder = ProposalBuilder()\n    mock_emb = {\"embedding\": [0.2] * 384, \"dimension\": 384, \"model\": \"all-MiniLM-L6-v2\", \"embedding_id\": \"emb-003\"}\n    with patch(\"hermes.proposal_builder.process_nlp\", new_callable=AsyncMock, side_effect=RuntimeError(\"spaCy unavailable\")), \\\n         patch(\"hermes.proposal_builder.generate_embedding\", new_callable=AsyncMock, return_value=mock_emb):\n        proposal = await builder.build(raw_text=\"Some text.\", metadata={})\n    assert proposal[\"proposed_nodes\"] == []\n    assert proposal[\"document_embedding\"][\"embedding\"] == [0.2] * 384\n\n\n@pytest.mark.asyncio\nasync def test_build_proposal_degrades_when_embedding_unavailable():\n    from hermes.proposal_builder import ProposalBuilder\n    builder = ProposalBuilder()\n    mock_nlp = {\"entities\": [{\"text\": \"Bob\", \"label\": \"PERSON\", \"start\": 0, \"end\": 3}]}\n    with patch(\"hermes.proposal_builder.process_nlp\", new_callable=AsyncMock, return_value=mock_nlp), \\\n         patch(\"hermes.proposal_builder.generate_embedding\", new_callable=AsyncMock, side_effect=RuntimeError(\"model not loaded\")):\n        proposal = await builder.build(raw_text=\"Bob went home.\", metadata={})\n    assert len(proposal[\"proposed_nodes\"]) == 1\n    assert proposal[\"proposed_nodes\"][0][\"embedding\"] is None\n    assert proposal[\"document_embedding\"] == {}\n```\n\n**Run:** `poetry run pytest tests/hermes/test_proposal_builder.py -v`\nExpected: 4 PASS",
    "status": "pending"
  },
  {
    "id": "02a",
    "group": "02-sophia-proposal-processing",
    "depends_on": [],
    "title": "Extend HermesProposal models for graph-ready fields",
    "description": "Add `proposed_nodes`, `proposed_relationships`, and `document_embedding` fields to `HermesProposalRequest`, and `relevant_context` to `HermesProposalResponse`.\n\n**Working directory:** `/home/fearsidhe/projects/LOGOS/sophia`\n\n**File:** `/home/fearsidhe/projects/LOGOS/sophia/src/sophia/api/models.py`\n\n`HermesProposalRequest` starts at line 450. Add these three fields after the existing `metadata` field (line 532):\n\n```python\n    # Graph-ready structured data (from Hermes ProposalBuilder)\n    proposed_nodes: Optional[List[Dict[str, Any]]] = Field(\n        default=None,\n        description=\"Graph-ready nodes with embeddings from Hermes NER pipeline\",\n    )\n    proposed_relationships: Optional[List[Dict[str, Any]]] = Field(\n        default=None,\n        description=\"Proposed edges between entities\",\n    )\n    document_embedding: Optional[Dict[str, Any]] = Field(\n        default=None,\n        description=\"Document-level embedding for similarity search\",\n    )\n```\n\n`HermesProposalResponse` starts at line 535. Add this field after `validation_results` (line 554):\n\n```python\n    relevant_context: Optional[List[Dict[str, Any]]] = Field(\n        default=None,\n        description=\"Relevant existing graph context returned to Hermes for prompt enrichment\",\n    )\n```\n\nAll new fields are `Optional` with `default=None` so existing callers are unaffected.\n\n**Test file:** Existing file at `/home/fearsidhe/projects/LOGOS/sophia/tests/unit/api/test_hermes_ingestion.py` — add these tests (or create the file if it doesn't have these):\n\n```python\nfrom sophia.api.models import HermesProposalRequest, HermesProposalResponse\n\n\ndef test_proposal_request_accepts_proposed_nodes():\n    req = HermesProposalRequest(\n        proposal_id=\"p-001\", llm_provider=\"openai\", model=\"gpt-4o-mini\",\n        generated_at=\"2026-01-01T00:00:00Z\", confidence=0.8,\n        proposed_nodes=[{\"name\": \"Alice\", \"type\": \"PERSON\", \"embedding\": [0.1] * 384,\n                         \"embedding_id\": \"e1\", \"dimension\": 384, \"model\": \"all-MiniLM-L6-v2\", \"properties\": {}}],\n        proposed_relationships=[],\n        document_embedding={\"embedding\": [0.2] * 384, \"embedding_id\": \"e2\", \"dimension\": 384, \"model\": \"all-MiniLM-L6-v2\"},\n    )\n    assert len(req.proposed_nodes) == 1\n    assert req.document_embedding[\"dimension\"] == 384\n\n\ndef test_proposal_request_nodes_optional():\n    req = HermesProposalRequest(\n        proposal_id=\"p-002\", llm_provider=\"echo\", model=\"echo\",\n        generated_at=\"2026-01-01T00:00:00Z\", confidence=0.5,\n    )\n    assert req.proposed_nodes is None\n    assert req.proposed_relationships is None\n    assert req.document_embedding is None\n\n\ndef test_proposal_response_includes_relevant_context():\n    resp = HermesProposalResponse(\n        proposal_id=\"p-001\", stored_node_ids=[\"uuid-1\"], status=\"accepted\",\n        relevant_context=[{\"node_uuid\": \"u1\", \"node_name\": \"Robotics\", \"node_type\": \"CONCEPT\", \"score\": 0.92, \"properties\": {}}],\n    )\n    assert len(resp.relevant_context) == 1\n    assert resp.relevant_context[0][\"score\"] == 0.92\n```\n\n**Run:** `poetry run pytest tests/unit/api/test_hermes_ingestion.py -v`\n**Also run:** `poetry run pytest tests/unit/ -v --timeout=30` to confirm no regressions.",
    "status": "pending"
  },
  {
    "id": "02b",
    "group": "02-sophia-proposal-processing",
    "depends_on": ["02a"],
    "title": "Implement EmbeddingStore (Sophia Milvus wrapper)",
    "description": "Create `/home/fearsidhe/projects/LOGOS/sophia/src/sophia/hcg_client/embedding_store.py` — a Milvus wrapper that stores and searches node embeddings, linking back to Neo4j via `node_uuid`.\n\n**Working directory:** `/home/fearsidhe/projects/LOGOS/sophia`\n\n**Context:**\n- Sophia's `hcg_client/client.py` imports pymilvus (line 25-28, optional import) but only uses it for health check\n- Hermes Milvus schema: fields are `embedding_id` (VARCHAR PK), `embedding` (FLOAT_VECTOR 384d), `model` (VARCHAR), `text` (VARCHAR), `timestamp` (INT64)\n- We add `node_uuid` (VARCHAR) to link embeddings back to Neo4j nodes\n- Collection name: `sophia_node_embeddings`\n- Embedding dimension: 384 (all-MiniLM-L6-v2)\n\n**Implementation:** Create `/home/fearsidhe/projects/LOGOS/sophia/src/sophia/hcg_client/embedding_store.py`:\n\n```python\n\"\"\"Milvus collection management for Sophia's HCG embeddings.\"\"\"\n\nimport logging\nfrom pymilvus import (\n    Collection, CollectionSchema, DataType, FieldSchema,\n    connections, utility,\n)\n\nlogger = logging.getLogger(__name__)\nCOLLECTION_NAME = \"sophia_node_embeddings\"\nEMBEDDING_DIM = 384\n\n\nclass EmbeddingStore:\n    \"\"\"Manages Milvus collection for HCG node embeddings.\"\"\"\n\n    def __init__(self, host: str = \"localhost\", port: int = 19530):\n        self._host = host\n        self._port = port\n        self._collection: Collection | None = None\n        self._initialized = False\n\n    def initialize(self) -> None:\n        connections.connect(alias=\"sophia\", host=self._host, port=self._port)\n        if utility.has_collection(COLLECTION_NAME, using=\"sophia\"):\n            self._collection = Collection(COLLECTION_NAME, using=\"sophia\")\n        else:\n            schema = self._build_schema()\n            self._collection = Collection(COLLECTION_NAME, schema, using=\"sophia\")\n            self._collection.create_index(\n                \"embedding\",\n                {\"index_type\": \"IVF_FLAT\", \"metric_type\": \"L2\", \"params\": {\"nlist\": 128}},\n            )\n        self._collection.load()\n        self._initialized = True\n\n    def _build_schema(self) -> CollectionSchema:\n        fields = [\n            FieldSchema(name=\"embedding_id\", dtype=DataType.VARCHAR, is_primary=True, max_length=64),\n            FieldSchema(name=\"node_uuid\", dtype=DataType.VARCHAR, max_length=64),\n            FieldSchema(name=\"embedding\", dtype=DataType.FLOAT_VECTOR, dim=EMBEDDING_DIM),\n            FieldSchema(name=\"model\", dtype=DataType.VARCHAR, max_length=128),\n            FieldSchema(name=\"text\", dtype=DataType.VARCHAR, max_length=4096),\n        ]\n        return CollectionSchema(fields, description=\"Sophia HCG node embeddings\")\n\n    def store_embedding(self, *, node_uuid: str, embedding: list[float],\n                        embedding_id: str, text: str, model: str, dimension: int = EMBEDDING_DIM) -> None:\n        if not self._initialized or self._collection is None:\n            raise RuntimeError(\"EmbeddingStore not initialized\")\n        self._collection.insert([{\n            \"embedding_id\": embedding_id, \"node_uuid\": node_uuid,\n            \"embedding\": embedding, \"model\": model, \"text\": text[:4096],\n        }])\n\n    def search_similar(self, query_embedding: list[float], top_k: int = 10) -> list[dict]:\n        if not self._initialized or self._collection is None:\n            raise RuntimeError(\"EmbeddingStore not initialized\")\n        results = self._collection.search(\n            data=[query_embedding], anns_field=\"embedding\",\n            param={\"metric_type\": \"L2\", \"params\": {\"nprobe\": 10}},\n            limit=top_k, output_fields=[\"node_uuid\"],\n        )\n        return [{\"node_uuid\": hit.entity.get(\"node_uuid\"), \"score\": 1.0 - hit.distance} for hit in results[0]]\n```\n\n**Test file:** Create `/home/fearsidhe/projects/LOGOS/sophia/tests/unit/hcg_client/__init__.py` (empty) and `/home/fearsidhe/projects/LOGOS/sophia/tests/unit/hcg_client/test_embedding_store.py`:\n\n```python\n\"\"\"Tests for EmbeddingStore.\"\"\"\nimport pytest\nfrom unittest.mock import MagicMock\n\n\ndef test_embedding_store_schema():\n    from sophia.hcg_client.embedding_store import EmbeddingStore\n    store = EmbeddingStore.__new__(EmbeddingStore)\n    schema = store._build_schema()\n    field_names = [f.name for f in schema.fields]\n    assert \"embedding_id\" in field_names\n    assert \"node_uuid\" in field_names\n    assert \"embedding\" in field_names\n\n\ndef test_store_embedding_calls_insert():\n    from sophia.hcg_client.embedding_store import EmbeddingStore\n    mock_collection = MagicMock()\n    store = EmbeddingStore.__new__(EmbeddingStore)\n    store._collection = mock_collection\n    store._initialized = True\n    store.store_embedding(node_uuid=\"n-001\", embedding=[0.1] * 384,\n                          embedding_id=\"e-001\", text=\"test\", model=\"all-MiniLM-L6-v2\", dimension=384)\n    mock_collection.insert.assert_called_once()\n\n\ndef test_search_similar_returns_results():\n    from sophia.hcg_client.embedding_store import EmbeddingStore\n    mock_hit = MagicMock()\n    mock_hit.distance = 0.15\n    mock_hit.entity.get.return_value = \"n-001\"\n    mock_collection = MagicMock()\n    mock_collection.search.return_value = [[mock_hit]]\n    store = EmbeddingStore.__new__(EmbeddingStore)\n    store._collection = mock_collection\n    store._initialized = True\n    results = store.search_similar(query_embedding=[0.1] * 384, top_k=5)\n    assert len(results) == 1\n    assert results[0][\"node_uuid\"] == \"n-001\"\n    assert results[0][\"score\"] == pytest.approx(0.85, abs=0.01)\n```\n\n**Run:** `poetry run pytest tests/unit/hcg_client/test_embedding_store.py -v`",
    "status": "pending"
  },
  {
    "id": "02c",
    "group": "02-sophia-proposal-processing",
    "depends_on": ["02a", "02b"],
    "title": "Implement ProposalProcessor and wire into ingestion endpoint",
    "description": "Create `/home/fearsidhe/projects/LOGOS/sophia/src/sophia/ingestion/proposal_processor.py` and update the `/ingest/hermes_proposal` endpoint in `app.py` to delegate to it.\n\n**Working directory:** `/home/fearsidhe/projects/LOGOS/sophia`\n\n**Context:**\n- `HCGClient.add_node(name, node_type, uuid, properties, *, source, derivation, confidence, tags, links) -> str` at `hcg_client/client.py:92`. Note: `ancestors` and `is_type_definition` are also params.\n- `HCGClient.add_edge(edge_id, source_uuid, target_uuid, relation, properties) -> str` at `client.py:292`\n- `EmbeddingStore.store_embedding(*, node_uuid, embedding, embedding_id, text, model, dimension)` from task 02b\n- `EmbeddingStore.search_similar(query_embedding, top_k) -> list[dict]` from task 02b\n- Current `ingest_hermes_proposal()` at `app.py:1233` only logs and returns `stored_node_ids=[]`\n- `_feedback_dispatcher` already initialized in app.py, used to emit B1 feedback\n\n**Implementation:** Create `sophia/src/sophia/ingestion/__init__.py` (empty) and `sophia/src/sophia/ingestion/proposal_processor.py`:\n\n```python\n\"\"\"Cognitive intake logic for Hermes proposals.\"\"\"\nimport logging\nimport uuid as uuid_mod\nfrom dataclasses import dataclass, field\nfrom sophia.api.models import HermesProposalRequest\n\nlogger = logging.getLogger(__name__)\n\n\n@dataclass\nclass ProposalResult:\n    stored_node_ids: list[str] = field(default_factory=list)\n    relevant_context: list[dict] = field(default_factory=list)\n\n\nclass ProposalProcessor:\n    def __init__(self, hcg_client, embedding_store):\n        self._hcg = hcg_client\n        self._embeddings = embedding_store\n\n    def process(self, request: HermesProposalRequest) -> ProposalResult:\n        result = ProposalResult()\n\n        # 1. Retrieve relevant context via document embedding\n        doc_emb = request.document_embedding\n        if doc_emb and doc_emb.get(\"embedding\"):\n            try:\n                similar = self._embeddings.search_similar(\n                    query_embedding=doc_emb[\"embedding\"], top_k=10)\n                for match in similar:\n                    try:\n                        node_data = self._hcg.get_node(match[\"node_uuid\"])\n                        result.relevant_context.append({\n                            \"node_uuid\": match[\"node_uuid\"],\n                            \"node_name\": node_data.get(\"name\", \"\"),\n                            \"node_type\": node_data.get(\"type\", \"\"),\n                            \"score\": match[\"score\"],\n                            \"properties\": node_data.get(\"properties\", {}),\n                        })\n                    except Exception as e:\n                        logger.warning(f\"Failed to fetch node {match['node_uuid']}: {e}\")\n                        result.relevant_context.append({\"node_uuid\": match[\"node_uuid\"], \"score\": match[\"score\"]})\n            except Exception as e:\n                logger.warning(f\"Embedding search failed: {e}\")\n\n        # 2. Ingest proposed nodes\n        for node in (request.proposed_nodes or []):\n            name = node.get(\"name\", \"\").strip()\n            if not name:\n                continue\n            node_uuid = str(uuid_mod.uuid4())\n            try:\n                stored_uuid = self._hcg.add_node(\n                    name=name, node_type=node.get(\"type\", \"UNKNOWN\"), uuid=node_uuid,\n                    properties=node.get(\"properties\", {}), source=request.source_service,\n                    derivation=(request.metadata or {}).get(\"derivation\", \"observed\"),\n                    confidence=request.confidence, tags=[], links={},\n                )\n                result.stored_node_ids.append(stored_uuid)\n                embedding = node.get(\"embedding\")\n                embedding_id = node.get(\"embedding_id\")\n                if embedding and embedding_id:\n                    try:\n                        self._embeddings.store_embedding(\n                            node_uuid=stored_uuid, embedding=embedding,\n                            embedding_id=embedding_id, text=name,\n                            model=node.get(\"model\", \"unknown\"),\n                            dimension=node.get(\"dimension\", 384),\n                        )\n                    except Exception as e:\n                        logger.warning(f\"Failed to store embedding for {name}: {e}\")\n            except Exception as e:\n                logger.error(f\"Failed to create node '{name}': {e}\")\n\n        return result\n```\n\n**Endpoint wiring:** In `sophia/src/sophia/api/app.py`, modify `ingest_hermes_proposal()` (line 1233). Replace the body with:\n\n```python\nasync def ingest_hermes_proposal(request: HermesProposalRequest) -> HermesProposalResponse:\n    logger.info(f\"Received Hermes proposal: {request.proposal_id}\")\n    stored_node_ids = []\n    relevant_context = None\n    if _proposal_processor is not None:\n        try:\n            result = _proposal_processor.process(request)\n            stored_node_ids = result.stored_node_ids\n            relevant_context = result.relevant_context\n        except Exception as e:\n            logger.error(f\"Proposal processing failed: {e}\")\n    if _feedback_dispatcher is not None:\n        try:\n            from sophia.feedback.models import FeedbackPayload\n            _feedback_dispatcher.emit(FeedbackPayload(\n                correlation_id=request.correlation_id,\n                feedback_type=\"observation\",\n                outcome=\"accepted\" if stored_node_ids else \"created\",\n                reason=f\"Processed proposal {request.proposal_id}\",\n                node_ids_created=stored_node_ids,\n            ))\n        except Exception as e:\n            logger.warning(f\"Feedback emission failed: {e}\")\n    return HermesProposalResponse(\n        proposal_id=request.proposal_id, stored_node_ids=stored_node_ids,\n        status=\"accepted\", relevant_context=relevant_context,\n    )\n```\n\nAlso add near the existing `_feedback_dispatcher` initialization (search for `_feedback_dispatcher = ` in app.py):\n\n```python\n_proposal_processor = None\ntry:\n    from sophia.ingestion.proposal_processor import ProposalProcessor\n    from sophia.hcg_client.embedding_store import EmbeddingStore\nexcept ImportError:\n    pass\n```\n\nThe actual initialization happens when HCG client and Milvus are available during app startup.\n\n**Test file:** Create `sophia/tests/unit/ingestion/__init__.py` (empty) and `sophia/tests/unit/ingestion/test_proposal_processor.py`:\n\n```python\n\"\"\"Tests for ProposalProcessor.\"\"\"\nfrom unittest.mock import MagicMock\nfrom sophia.api.models import HermesProposalRequest\n\n\ndef _make_proposal(**overrides):\n    defaults = {\n        \"proposal_id\": \"p-001\", \"llm_provider\": \"openai\", \"model\": \"gpt-4o-mini\",\n        \"generated_at\": \"2026-01-01T00:00:00Z\", \"confidence\": 0.8,\n        \"proposed_nodes\": [{\"name\": \"Alice\", \"type\": \"PERSON\", \"embedding\": [0.1] * 384,\n                            \"embedding_id\": \"e1\", \"dimension\": 384, \"model\": \"m\", \"properties\": {}}],\n        \"proposed_relationships\": [],\n        \"document_embedding\": {\"embedding\": [0.2] * 384, \"embedding_id\": \"ed\", \"dimension\": 384, \"model\": \"m\"},\n        \"metadata\": {\"source\": \"hermes_llm\", \"derivation\": \"observed\"},\n    }\n    defaults.update(overrides)\n    return HermesProposalRequest(**defaults)\n\n\ndef test_process_creates_nodes():\n    from sophia.ingestion.proposal_processor import ProposalProcessor\n    mock_hcg = MagicMock()\n    mock_hcg.add_node.return_value = \"uuid-001\"\n    mock_emb = MagicMock()\n    mock_emb.search_similar.return_value = []\n    result = ProposalProcessor(mock_hcg, mock_emb).process(_make_proposal())\n    assert \"uuid-001\" in result.stored_node_ids\n    mock_hcg.add_node.assert_called_once()\n\n\ndef test_process_stores_embeddings():\n    from sophia.ingestion.proposal_processor import ProposalProcessor\n    mock_hcg = MagicMock()\n    mock_hcg.add_node.return_value = \"uuid-001\"\n    mock_emb = MagicMock()\n    mock_emb.search_similar.return_value = []\n    ProposalProcessor(mock_hcg, mock_emb).process(_make_proposal())\n    mock_emb.store_embedding.assert_called_once()\n    assert mock_emb.store_embedding.call_args[1][\"node_uuid\"] == \"uuid-001\"\n\n\ndef test_process_searches_context():\n    from sophia.ingestion.proposal_processor import ProposalProcessor\n    mock_hcg = MagicMock()\n    mock_hcg.add_node.return_value = \"uuid-001\"\n    mock_hcg.get_node.return_value = {\"uuid\": \"ex-001\", \"name\": \"Robotics\", \"type\": \"CONCEPT\", \"properties\": {}}\n    mock_emb = MagicMock()\n    mock_emb.search_similar.return_value = [{\"node_uuid\": \"ex-001\", \"score\": 0.92}]\n    result = ProposalProcessor(mock_hcg, mock_emb).process(_make_proposal())\n    assert len(result.relevant_context) == 1\n    assert result.relevant_context[0][\"score\"] == 0.92\n\n\ndef test_process_skips_empty_names():\n    from sophia.ingestion.proposal_processor import ProposalProcessor\n    mock_hcg = MagicMock()\n    mock_emb = MagicMock()\n    mock_emb.search_similar.return_value = []\n    result = ProposalProcessor(mock_hcg, mock_emb).process(\n        _make_proposal(proposed_nodes=[{\"name\": \"\", \"type\": \"X\", \"embedding\": None,\n                                        \"embedding_id\": None, \"dimension\": None, \"model\": None, \"properties\": {}}]))\n    assert result.stored_node_ids == []\n\n\ndef test_process_handles_legacy_format():\n    from sophia.ingestion.proposal_processor import ProposalProcessor\n    mock_hcg = MagicMock()\n    mock_emb = MagicMock()\n    mock_emb.search_similar.return_value = []\n    result = ProposalProcessor(mock_hcg, mock_emb).process(\n        _make_proposal(proposed_nodes=None, document_embedding=None))\n    assert result.stored_node_ids == []\n```\n\n**Run:** `poetry run pytest tests/unit/ingestion/test_proposal_processor.py -v`\n**Also run:** `poetry run pytest tests/unit/ -v --timeout=30` for regression check.",
    "status": "pending"
  },
  {
    "id": "03a",
    "group": "03-hermes-loop-integration",
    "depends_on": ["01a", "02c"],
    "title": "Refactor /llm to proposal-first with context injection",
    "description": "Refactor `llm_generate()` in `/home/fearsidhe/projects/LOGOS/hermes/src/hermes/main.py` so the flow is: build proposal → send to Sophia → receive context → inject into LLM prompt → generate. Replace the old post-generation forwarding.\n\n**Working directory:** `/home/fearsidhe/projects/LOGOS/hermes`\n\n**Current state (to be replaced):**\n- `llm_generate()` at line 544: calls `generate_llm_response()` THEN calls `_forward_llm_to_sophia()` with the result\n- `_forward_llm_to_sophia()` at line 479: sends raw text to Sophia after generation\n\n**New flow:**\n1. Extract user's latest message\n2. Build proposal via `ProposalBuilder.build()` (from task 01a)\n3. Send proposal to Sophia `/ingest/hermes_proposal`, receive `relevant_context`\n4. Translate context to system message via `_build_context_message()`\n5. Inject context message into conversation\n6. Call `generate_llm_response()` with enriched messages\n7. Return response (no post-generation forwarding)\n\n**Add these new functions before `llm_generate`:**\n\n```python\nfrom hermes.proposal_builder import ProposalBuilder\n\n\ndef _build_context_message(relevant_context: list[dict]) -> dict:\n    \"\"\"Translate Sophia's graph context into a system message for the LLM.\"\"\"\n    if not relevant_context:\n        return {\"role\": \"system\", \"content\": \"\"}\n    lines = [\"Relevant knowledge from memory:\"]\n    for ctx in relevant_context:\n        name = ctx.get(\"node_name\", \"unknown\")\n        node_type = ctx.get(\"node_type\", \"unknown\")\n        score = ctx.get(\"score\", 0.0)\n        lines.append(f\"- {name} ({node_type}, relevance: {score:.2f})\")\n    return {\"role\": \"system\", \"content\": \"\\n\".join(lines)}\n\n\nasync def _send_proposal_to_sophia(proposal: dict) -> dict | None:\n    \"\"\"Send structured proposal to Sophia, return response with relevant_context.\"\"\"\n    import httpx\n    sophia_host = get_env_value(\"SOPHIA_HOST\", default=\"localhost\") or \"localhost\"\n    sophia_port = get_env_value(\"SOPHIA_PORT\", default=\"8001\") or \"8001\"\n    sophia_url = f\"http://{sophia_host}:{sophia_port}\"\n    sophia_token = get_env_value(\"SOPHIA_API_KEY\") or get_env_value(\"SOPHIA_API_TOKEN\")\n    if not sophia_token:\n        logger.debug(\"Sophia API token not configured, skipping proposal\")\n        return None\n    try:\n        async with httpx.AsyncClient(timeout=10.0) as client:\n            response = await client.post(\n                f\"{sophia_url}/ingest/hermes_proposal\", json=proposal,\n                headers={\"Authorization\": f\"Bearer {sophia_token}\"},\n            )\n            if response.status_code == 201:\n                return response.json()\n            logger.warning(f\"Sophia rejected proposal: {response.status_code}\")\n            return None\n    except Exception as exc:\n        logger.warning(f\"Failed to send proposal to Sophia: {exc}\")\n        return None\n```\n\n**Replace `llm_generate()` body (keep the decorator):**\n\n```python\n@app.post(\"/llm\", response_model=LLMResponse)\nasync def llm_generate(request: LLMRequest, http_request: Request) -> LLMResponse:\n    normalized_messages: List[LLMMessage] = list(request.messages or [])\n    if not normalized_messages:\n        prompt = (request.prompt or \"\").strip()\n        if not prompt:\n            raise HTTPException(status_code=400, detail=\"Either 'prompt' or 'messages' must be provided.\")\n        normalized_messages = [LLMMessage(role=\"user\", content=prompt)]\n\n    request_id = getattr(http_request.state, \"request_id\", str(uuid.uuid4()))\n\n    # Extract user's latest message for proposal\n    user_text = \"\"\n    for msg in reversed(normalized_messages):\n        if msg.role == \"user\":\n            user_text = msg.content\n            break\n\n    # Build proposal and query Sophia for context\n    context_message = None\n    if user_text:\n        try:\n            builder = ProposalBuilder()\n            proposal = await builder.build(\n                raw_text=user_text, metadata={\"source\": \"hermes_llm\", \"derivation\": \"observed\"},\n                correlation_id=request_id, llm_provider=request.provider or \"unknown\",\n                model=request.model or \"unknown\",\n            )\n            sophia_response = await _send_proposal_to_sophia(proposal)\n            if sophia_response and sophia_response.get(\"relevant_context\"):\n                context_message = _build_context_message(sophia_response[\"relevant_context\"])\n        except Exception as e:\n            logger.warning(f\"Proposal/context flow failed, generating without context: {e}\")\n\n    # Inject context into messages\n    enriched_messages = list(normalized_messages)\n    if context_message and context_message.get(\"content\"):\n        enriched_messages.insert(0, LLMMessage(**context_message))\n\n    try:\n        result = await generate_llm_response(\n            messages=[msg.model_dump(exclude_none=True) for msg in enriched_messages],\n            provider=request.provider, model=request.model,\n            temperature=request.temperature, max_tokens=request.max_tokens,\n            metadata=request.metadata,\n        )\n        return LLMResponse(**result)\n    except LLMProviderNotConfiguredError as exc:\n        raise HTTPException(status_code=503, detail=str(exc)) from exc\n    except LLMProviderError as exc:\n        raise HTTPException(status_code=502, detail=str(exc)) from exc\n    except Exception as exc:\n        logger.error(\"LLM endpoint failure: %s\", str(exc))\n        raise HTTPException(status_code=500, detail=\"LLM provider failure\") from exc\n```\n\n**Remove** the old `_forward_llm_to_sophia()` function entirely (lines 479-541).\n\n**Test file:** Create `/home/fearsidhe/projects/LOGOS/hermes/tests/hermes/test_context_injection.py`:\n\n```python\n\"\"\"Tests for per-turn context injection.\"\"\"\nimport pytest\nfrom unittest.mock import AsyncMock, patch\n\n\ndef test_build_context_message_translates_nodes():\n    from hermes.main import _build_context_message\n    msg = _build_context_message([\n        {\"node_name\": \"Alice\", \"node_type\": \"PERSON\", \"score\": 0.95, \"properties\": {}},\n        {\"node_name\": \"Robotics Lab\", \"node_type\": \"ORG\", \"score\": 0.82, \"properties\": {}},\n    ])\n    assert msg[\"role\"] == \"system\"\n    assert \"Alice\" in msg[\"content\"]\n    assert \"PERSON\" in msg[\"content\"]\n    assert \"Robotics Lab\" in msg[\"content\"]\n\n\ndef test_build_context_message_empty():\n    from hermes.main import _build_context_message\n    msg = _build_context_message([])\n    assert msg[\"content\"] == \"\"\n\n\n@pytest.mark.asyncio\nasync def test_send_proposal_returns_none_without_token():\n    from hermes.main import _send_proposal_to_sophia\n    with patch(\"hermes.main.get_env_value\", return_value=None):\n        result = await _send_proposal_to_sophia({\"proposal_id\": \"p-001\"})\n    assert result is None\n\n\n@pytest.mark.asyncio\nasync def test_send_proposal_returns_none_on_connection_error():\n    from hermes.main import _send_proposal_to_sophia\n    def mock_env(key, **kwargs):\n        return {\"SOPHIA_HOST\": \"localhost\", \"SOPHIA_PORT\": \"9999\",\n                \"SOPHIA_API_KEY\": \"test-token\", \"SOPHIA_API_TOKEN\": \"test-token\"}.get(key, kwargs.get(\"default\"))\n    with patch(\"hermes.main.get_env_value\", side_effect=mock_env), \\\n         patch(\"httpx.AsyncClient.post\", new_callable=AsyncMock, side_effect=Exception(\"refused\")):\n        result = await _send_proposal_to_sophia({\"proposal_id\": \"p-001\"})\n    assert result is None\n```\n\n**Run:** `poetry run pytest tests/hermes/test_context_injection.py -v`\n**Also run:** `poetry run pytest tests/ -v --timeout=30` — update any existing tests that assert on the old `_forward_llm_to_sophia` behavior (it no longer exists).",
    "status": "pending"
  },
  {
    "id": "03b",
    "group": "03-hermes-loop-integration",
    "depends_on": ["00b"],
    "title": "Fix feedback persistence to Redis (hermes#17)",
    "description": "Make the `/feedback` endpoint in hermes persist payloads to Redis instead of only logging them.\n\n**Working directory:** `/home/fearsidhe/projects/LOGOS/hermes`\n\n**Current state:** `receive_feedback()` at `main.py:808` only logs structured feedback fields and returns `FeedbackResponse(status='accepted')`. No storage.\n\n**Depends on:** Task 00a (RedisConfig exists in logos_config) and task 00b (Redis in hermes test compose).\n\n**Implementation:**\n\nIn `/home/fearsidhe/projects/LOGOS/hermes/src/hermes/main.py`:\n\n1. Add import near the top:\n```python\nimport redis as redis_lib\n```\n\n2. Add Redis initialization after the existing app setup (after `app.add_middleware(RequestIDMiddleware)`):\n```python\n# Initialize Redis for feedback storage (optional)\n_feedback_redis = None\ntry:\n    from logos_config import RedisConfig\n    _redis_config = RedisConfig()\n    _feedback_redis = redis_lib.from_url(_redis_config.url)\n    _feedback_redis.ping()\n    logger.info(f\"Feedback Redis connected: {_redis_config.url}\")\nexcept Exception as e:\n    logger.info(f\"Feedback Redis not available (log-only mode): {e}\")\n    _feedback_redis = None\n\nFEEDBACK_TTL_SECONDS = 86400 * 7  # 7 days\n```\n\n3. Replace the body of `receive_feedback()` (keep the decorator and signature):\n```python\n@app.post(\"/feedback\", response_model=FeedbackResponse, status_code=201)\nasync def receive_feedback(payload: FeedbackPayload, request: Request) -> FeedbackResponse:\n    request_id = getattr(request.state, \"request_id\", \"unknown\")\n    logger.info(\"Received feedback\", extra={\n        \"request_id\": request_id, \"feedback_type\": payload.feedback_type,\n        \"outcome\": payload.outcome, \"correlation_id\": payload.correlation_id,\n    })\n    if _feedback_redis is not None:\n        try:\n            key = f\"hermes:feedback:{payload.correlation_id or payload.plan_id or payload.execution_id}\"\n            _feedback_redis.hset(key, mapping=payload.model_dump(mode=\"json\", exclude_none=True))\n            _feedback_redis.expire(key, FEEDBACK_TTL_SECONDS)\n        except Exception as e:\n            logger.warning(f\"Failed to persist feedback to Redis: {e}\")\n    return FeedbackResponse(status=\"accepted\",\n                            message=f\"Feedback received for {payload.feedback_type}: {payload.outcome}\")\n```\n\n**Note:** `redis` package must be in hermes dependencies. Check `pyproject.toml` — if missing, add `redis = \">=5.0\"` to `[tool.poetry.dependencies]`.\n\n**Test file:** Create `/home/fearsidhe/projects/LOGOS/hermes/tests/hermes/test_feedback.py`:\n\n```python\n\"\"\"Tests for /feedback endpoint persistence.\"\"\"\nimport pytest\nfrom unittest.mock import MagicMock, patch, AsyncMock\nimport asyncio\n\n\ndef _make_feedback():\n    from hermes.main import FeedbackPayload\n    return FeedbackPayload(\n        correlation_id=\"corr-001\", feedback_type=\"observation\",\n        outcome=\"accepted\", reason=\"Node created\", node_ids_created=[\"uuid-001\"],\n    )\n\n\ndef _make_request():\n    req = MagicMock()\n    req.state.request_id = \"req-001\"\n    return req\n\n\n@pytest.mark.asyncio\nasync def test_feedback_stores_in_redis():\n    from hermes.main import receive_feedback\n    mock_redis = MagicMock()\n    with patch(\"hermes.main._feedback_redis\", mock_redis):\n        result = await receive_feedback(_make_feedback(), _make_request())\n    assert result.status == \"accepted\"\n    mock_redis.hset.assert_called_once()\n    assert \"corr-001\" in str(mock_redis.hset.call_args)\n\n\n@pytest.mark.asyncio\nasync def test_feedback_sets_ttl():\n    from hermes.main import receive_feedback, FEEDBACK_TTL_SECONDS\n    mock_redis = MagicMock()\n    with patch(\"hermes.main._feedback_redis\", mock_redis):\n        await receive_feedback(_make_feedback(), _make_request())\n    mock_redis.expire.assert_called_once()\n    assert mock_redis.expire.call_args[0][1] == FEEDBACK_TTL_SECONDS\n\n\n@pytest.mark.asyncio\nasync def test_feedback_works_without_redis():\n    from hermes.main import receive_feedback\n    with patch(\"hermes.main._feedback_redis\", None):\n        result = await receive_feedback(_make_feedback(), _make_request())\n    assert result.status == \"accepted\"\n```\n\n**Run:** `poetry run pytest tests/hermes/test_feedback.py -v`",
    "status": "pending"
  }
]
